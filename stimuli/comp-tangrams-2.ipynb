{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ws/home/jmankewitz/miniconda3/envs/shape-comp/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIPModel(\n",
       "  (text_model): CLIPTextTransformer(\n",
       "    (embeddings): CLIPTextEmbeddings(\n",
       "      (token_embedding): Embedding(49408, 512)\n",
       "      (position_embedding): Embedding(77, 512)\n",
       "    )\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (vision_model): CLIPVisionTransformer(\n",
       "    (embeddings): CLIPVisionEmbeddings(\n",
       "      (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "      (position_embedding): Embedding(50, 768)\n",
       "    )\n",
       "    (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (visual_projection): Linear(in_features=768, out_features=512, bias=False)\n",
       "  (text_projection): Linear(in_features=512, out_features=512, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1_preprocess = processor(Image.open(image1)).unsqueeze(0).to(device)\n",
    "image1_features = model.encode_image(image1_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ws/home/jmankewitz/miniconda3/envs/shape-comp/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import requests\n",
    "\n",
    "from transformers import AutoProcessor, CLIPVisionModelWithProjection\n",
    "\n",
    "model = CLIPVisionModelWithProjection.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "#processor = AutoProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model(**inputs)\n",
    "\n",
    "image_embeds = outputs.image_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0570e-01,  1.3791e-01, -2.9611e-01,  2.1249e-02, -6.4070e-02,\n",
       "         -1.6862e-01, -1.3514e-01, -2.4484e-03,  4.7376e-01, -1.7627e-01,\n",
       "          2.4440e-01, -3.7972e-01,  4.8327e-02, -1.3981e-01, -3.4045e-01,\n",
       "         -1.2676e-01, -2.3266e-01, -2.9760e-01,  1.7886e-01,  4.9608e-02,\n",
       "         -1.3074e+00, -3.2437e-02,  4.2144e-01, -3.3363e-01, -4.7374e-02,\n",
       "          2.9805e-01,  2.3910e-01, -1.8429e-01,  1.5669e-01, -4.8810e-02,\n",
       "         -7.7587e-02,  2.5888e-01, -7.3553e-02,  1.7692e-01, -5.7918e-01,\n",
       "         -4.9198e-03,  2.7906e-01, -2.8707e-01,  1.9080e-01,  3.2633e-01,\n",
       "         -1.0051e-01, -3.4647e-01,  7.1662e-03, -1.4746e-01, -1.9010e-01,\n",
       "          5.7525e-04,  5.2022e-01,  1.5117e-01, -9.1645e-02,  1.7595e-01,\n",
       "          1.6325e-01,  2.5157e-01,  1.1609e-01, -5.3788e-02,  2.2871e-01,\n",
       "          1.8608e-01,  2.5763e-01,  6.0314e-01, -2.5823e-01, -1.6781e-01,\n",
       "          4.2385e-01, -1.3951e-01, -6.3742e-02,  3.5568e-01, -7.4244e-02,\n",
       "         -2.7096e-01,  2.2417e-01,  1.0962e+00,  1.9659e-01,  7.8918e-02,\n",
       "          2.0099e-01, -1.0657e-01,  2.7643e-01,  2.7661e-01,  4.9342e-01,\n",
       "         -1.6944e-02,  6.3949e-02, -3.4031e-01, -5.2761e-02, -1.3829e-01,\n",
       "         -1.8781e-01, -6.7633e-01, -4.5840e-01, -1.5787e-02, -5.5268e-01,\n",
       "          2.6263e-01,  4.3102e-01, -5.3736e-01,  2.9391e-01,  9.3340e-02,\n",
       "          1.7963e-01,  2.7745e-02, -7.3421e+00,  3.2605e-01, -2.1535e-01,\n",
       "          6.7098e-02,  1.7348e-01, -4.2522e-01, -9.2658e-01,  1.2663e+00,\n",
       "         -2.9132e-02,  6.1214e-02, -3.0542e-01, -7.5490e-03,  7.2453e-01,\n",
       "          2.5023e-01,  1.2300e+00,  2.6843e-01, -1.8051e-01, -4.7297e-01,\n",
       "         -1.5611e-01, -1.0561e+00,  6.2212e-02,  1.9993e-01,  1.8817e-01,\n",
       "          5.9712e-02,  8.6169e-02,  1.1679e-01,  1.7643e-01, -1.0635e-01,\n",
       "          1.6236e-01, -2.1022e-01, -1.8189e-01,  3.9629e-01, -1.6404e-01,\n",
       "         -9.2917e-02, -6.0283e-02,  5.1839e-01, -1.2987e-01,  2.8776e-02,\n",
       "         -5.2972e-02,  7.8340e-02, -1.9674e-01,  9.4795e-01, -4.1044e-01,\n",
       "         -3.8089e-01,  1.4848e-01, -4.8702e-01, -4.1070e-01, -1.2976e-01,\n",
       "          1.5802e-01, -3.7492e-01,  3.5367e-01,  4.1437e-01, -1.5291e-01,\n",
       "          2.8547e-01,  3.2227e-01, -5.6265e-01,  8.8450e-02,  2.4728e-01,\n",
       "         -4.8397e-01,  1.8799e-01, -3.0984e-01, -2.2551e-01,  1.9980e-02,\n",
       "         -5.9366e-02, -3.3540e-01, -4.7573e-01,  1.1815e-01, -4.0058e-01,\n",
       "         -2.7257e-02, -2.6316e-01,  1.1217e-01,  2.2248e-01,  3.2533e-04,\n",
       "         -3.8470e-01, -5.2015e-01,  5.2815e-01,  1.4545e-01,  3.0454e-01,\n",
       "          2.2329e-01,  6.8722e-01,  3.0521e-01, -2.2130e-01, -2.1167e-01,\n",
       "          1.8806e-01,  2.2055e-02,  5.4690e-02,  6.9693e-02,  2.5776e-01,\n",
       "         -3.7218e-01,  2.3236e-01, -1.2269e-01, -3.6241e-01, -5.8700e-02,\n",
       "          1.3109e-01,  1.6811e-01, -3.7950e-01,  3.2862e-01, -1.7761e-01,\n",
       "          3.4697e-01, -2.8875e-01, -5.4294e-01, -1.3271e-01, -4.8734e-01,\n",
       "         -3.3036e-02, -2.6275e-01, -3.4988e-01, -1.1122e+00, -4.2773e-01,\n",
       "          4.3965e-02,  3.6076e-01,  1.3401e-01,  1.8443e-01, -1.0153e-01,\n",
       "         -1.2240e-02,  3.2831e-01,  6.7399e-02, -3.0257e-01,  5.6250e-01,\n",
       "         -4.1210e-01,  5.1786e-01, -3.5434e-02,  3.3271e-01, -4.2546e-01,\n",
       "         -3.5231e-01, -2.9017e-03, -7.1604e-01,  8.2598e-01, -3.9524e-01,\n",
       "          3.6176e-03,  1.5516e-01, -1.9975e-01,  1.6137e-01, -4.9928e-02,\n",
       "          3.6856e-01,  1.4779e-01, -6.9430e-02,  2.4153e-02, -1.9426e-01,\n",
       "         -1.5363e-01,  5.1794e-02, -3.3300e-01,  7.6162e-01,  2.7636e-01,\n",
       "         -5.3359e-01, -3.5004e-01,  1.3252e-01,  1.4886e-01, -1.8810e-01,\n",
       "          3.5506e-01, -1.8194e-01, -1.2301e-01, -2.9974e-02, -3.2487e-01,\n",
       "          6.2948e-01,  1.2428e-01, -4.6404e-02, -1.0913e-01,  7.0813e-01,\n",
       "          1.4804e-02,  2.7664e-01, -1.6041e-01, -7.4244e-02,  1.9206e-01,\n",
       "          4.8416e-02, -4.0808e-02, -2.7543e-01, -6.3991e-01, -4.4215e-02,\n",
       "         -8.5915e-02,  3.3263e-02, -3.5331e-03,  4.5338e-01,  3.2682e-01,\n",
       "         -1.0774e-01, -5.3721e-01, -4.2815e-01, -2.8198e-01,  6.1129e-02,\n",
       "         -2.4625e-01, -2.0745e-01,  3.1999e-01, -1.3205e-01, -2.2901e-01,\n",
       "         -1.8604e-01, -1.7491e-02,  1.7489e-01, -4.3999e-01,  1.0667e-01,\n",
       "          3.4010e-01,  2.5526e-01, -3.8551e-01, -6.2776e-02, -2.2571e-01,\n",
       "          7.5087e-02,  1.7720e-02, -1.3168e-02,  4.8330e-01, -1.9816e-01,\n",
       "         -1.4375e-01,  1.7780e-01,  2.7621e-01,  3.0707e-01,  1.8930e-01,\n",
       "          1.9520e-01,  2.6625e-01, -5.7480e-01,  7.9326e-03, -1.5115e-01,\n",
       "          2.3183e-01, -1.4169e-01, -1.1889e-01,  4.3253e-01, -9.8077e-02,\n",
       "          3.0851e-01, -6.7045e-02,  3.7698e-01,  8.8926e-02, -1.8221e-01,\n",
       "         -5.8740e-01,  2.7006e-01,  9.4688e-01, -6.2511e-02, -1.8787e-01,\n",
       "          2.5662e-01,  1.5217e-01,  4.8820e-01,  1.8438e-01,  2.5828e-01,\n",
       "         -1.9514e-01,  1.6153e+00, -5.8381e-01, -3.6166e-02, -2.4056e-01,\n",
       "         -1.3784e-01, -9.4207e-02,  5.7140e-01,  1.9949e-01,  2.6506e-02,\n",
       "          1.4178e-02, -1.5593e-01, -1.7336e-01, -1.4924e-01,  3.4075e-02,\n",
       "          5.3849e-01,  7.3388e-02,  1.1542e-01, -1.5296e-02, -2.2718e-02,\n",
       "         -1.9321e-02, -5.7205e-02,  2.1121e-01,  7.7404e-02,  2.0938e-01,\n",
       "         -4.9050e-01, -1.2306e-01,  1.6134e-01, -8.3677e-02,  3.4774e-02,\n",
       "          1.1503e-01, -2.2666e-01,  5.5620e-01, -4.0450e-01, -2.0487e-01,\n",
       "         -1.0600e-01, -2.7015e-01,  2.6361e-01,  2.0263e-01,  3.7978e-01,\n",
       "          1.5335e-01,  1.2605e-01,  5.0471e-04, -1.3195e-01, -4.7008e-01,\n",
       "          1.9779e-01,  2.9090e-01, -5.4812e-01,  5.8499e-01, -1.0590e-01,\n",
       "          4.7545e-01,  5.0500e-01, -2.1749e-01, -5.9405e-01,  3.2484e-01,\n",
       "         -1.5170e-01,  1.8060e+00,  7.1680e-02, -4.2355e-01, -7.4224e-02,\n",
       "          6.7890e-02, -5.1898e-01, -1.6756e-01,  4.2614e-01, -1.2730e-01,\n",
       "          1.6015e-02, -1.1366e-01, -4.3086e-01,  1.2056e-01, -8.4343e-01,\n",
       "         -3.2650e-01, -4.5064e-01,  1.1179e-01, -2.6111e-01,  1.9197e-01,\n",
       "          1.2052e-01,  4.5279e-01, -3.2545e-01, -3.5914e-01, -2.7329e-01,\n",
       "          3.7605e-02,  2.1050e-01,  4.3315e-01,  2.8789e-01,  9.5152e-02,\n",
       "         -3.6645e-02, -2.0286e-01, -4.5810e-01,  6.2415e-01,  3.4841e-02,\n",
       "          5.0372e-01,  7.9766e-01, -1.8451e-01,  2.6256e-01,  5.5962e-04,\n",
       "         -6.5547e-01, -3.3765e-01, -6.3588e-02, -4.0205e-02, -3.6788e-01,\n",
       "         -5.8009e-01,  3.2927e-01,  2.0086e-01,  4.2279e-01,  1.2953e-01,\n",
       "          2.4375e-03,  1.1159e-01, -3.7128e-01,  6.6182e-01,  2.8009e-01,\n",
       "         -3.2797e-01,  7.9389e-01, -5.1525e-01,  2.6869e-01, -4.8718e-02,\n",
       "         -5.8017e-01, -3.9886e-02,  4.2184e-01,  2.9164e-01,  1.2954e-02,\n",
       "         -1.1651e-01, -2.6768e-01,  6.7935e-02, -1.1775e-01,  3.4765e-01,\n",
       "         -3.4615e-02,  5.2754e-02, -2.9523e-01, -1.9536e-01, -4.1873e-01,\n",
       "         -5.5842e-01, -2.5225e-01, -5.3106e-01,  5.3523e-01, -1.2160e-01,\n",
       "         -3.0841e-01,  3.7261e-01,  4.4894e-01,  1.3557e-01,  4.5114e-01,\n",
       "         -3.2811e-01, -3.9681e-01,  8.4930e-02, -2.9096e-01,  4.1583e-01,\n",
       "          1.4222e-01, -2.9784e-01, -2.1871e-01, -1.9392e-01, -4.0934e-01,\n",
       "          4.2811e-01, -5.0897e-01, -4.1473e-01, -1.0547e-01, -6.7014e-01,\n",
       "         -4.8981e-01, -3.7619e-01, -1.3544e-01, -1.2337e-01, -7.2206e-01,\n",
       "         -6.2175e-02, -9.9811e-02,  5.5191e-02,  7.3064e-02,  2.4990e-01,\n",
       "          1.5880e-01, -2.0090e-01,  1.1332e-01, -2.5104e-01, -1.5370e-01,\n",
       "         -4.3505e-02, -8.5118e-02, -1.9082e-01, -4.1292e-01,  6.2387e-01,\n",
       "          1.9057e-01,  7.9786e-02,  3.0655e-01,  1.2087e-01,  1.3618e-01,\n",
       "         -1.6667e-01,  5.7030e-01, -3.0686e-01, -1.7335e-01,  7.3685e-02,\n",
       "         -2.2815e-01,  1.3495e-01, -4.4910e-01,  1.2777e-01,  8.6682e-01,\n",
       "         -1.4580e-02,  2.5632e-01]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_embeds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shape-comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
